{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arseniy-Polyakov/machine_learning_course/blob/main/Task_3_CNN_videos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eu4Ev3RQMQ7D"
      },
      "source": [
        "В данной работе будет проводиться классификация видеозаписей, где показывается русский жестовый язык (РЖЯ) на основе датасета [Slovo](https://www.kaggle.com/datasets/kapitanov/slovo) с помощью технологий CNN + RNN(LSTM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIrr1XaSMykM"
      },
      "source": [
        "Устанавливаем необходимые библиотеки для скачивания датасета через платформу kaggle, обработки данных и архитектуры модели сверточной и реккурентной нейронной сети"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tC5Bh8ZmvncO",
        "outputId": "1ae5c688-cc66-460b-df1a-b2ed676f1047"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting json_repair\n",
            "  Downloading json_repair-0.46.2-py3-none-any.whl.metadata (12 kB)\n",
            "Downloading json_repair-0.46.2-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: json_repair\n",
            "Successfully installed json_repair-0.46.2\n"
          ]
        }
      ],
      "source": [
        "!pip install json_repair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHeoQQtRzEjg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69a489a2-efcf-45ee-a05b-317fc902fe39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if event.key is 'enter':\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import os\n",
        "import cv2\n",
        "import kagglehub\n",
        "import json_repair\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from moviepy.editor import VideoFileClip\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, LSTM, Dense, Dropout, Input\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3MgUVrdND_S"
      },
      "source": [
        "Проходим авторизацию на платформе для получения полного доступа к датасету"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4wmJSOp3MYW"
      },
      "outputs": [],
      "source": [
        "kagglehub.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rfe770GhNNP1"
      },
      "source": [
        "Устанавлием датасет в облако google colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HjAi8YC70xJd",
        "outputId": "4978fbda-78bd-44ca-c824-6b9d9d125400"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/kaggle/input/slovo'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "slovo_dataset = kagglehub.dataset_download(\"kapitanov/slovo\")\n",
        "slovo_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4PZcPsYNdc2"
      },
      "source": [
        "Пишем функцию для обработки видео по кадрам и их нормализации: приведения к единому формату, выберем как вариант (112, 112). Также пропишем функцию паддинга для фреймов"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_with_padding(frame: list, target_size: tuple, padding_color: tuple) -> list:\n",
        "  \"\"\"\n",
        "  The function for resizing and padding video frames (due to the different length and width of each frame)\n",
        "  \"\"\"\n",
        "  try:\n",
        "    h, w = frame.shape[:2]\n",
        "    target_h, target_w = target_size\n",
        "\n",
        "    scale = min(target_w / w, target_h / h)\n",
        "    new_w, new_h = int(w * scale), int(h * scale)\n",
        "\n",
        "    resized_frame = cv2.resize(frame, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    delta_w = target_w - new_w\n",
        "    delta_h = target_h - new_h\n",
        "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
        "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
        "\n",
        "    padded_frame = cv2.copyMakeBorder(resized_frame, top, bottom, left, right, cv2.BORDER_CONSTANT, value=padding_color)\n",
        "  except:\n",
        "    print(\"ERROR\")\n",
        "  return padded_frame"
      ],
      "metadata": {
        "id": "4aIH54Sz4OUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "BK2KsdIWJdwq"
      },
      "outputs": [],
      "source": [
        "def extract_features(dir_path: str) -> list:\n",
        "  \"\"\"\n",
        "  The function for parsing videos into frames and resizing every frame\n",
        "  \"\"\"\n",
        "  dataset = []\n",
        "  max_frames = 100\n",
        "  videos = os.listdir(\"/content/samples/\")\n",
        "  for i in tqdm(range(len(videos))):\n",
        "    frames = []\n",
        "    clip = VideoFileClip(dir_path + videos[i])\n",
        "    for frame in clip.iter_frames():\n",
        "      if frame is None:\n",
        "        print(\"None значение\")\n",
        "        break\n",
        "      frame_resized = resize_with_padding(frame, (112, 112), (0, 0, 0))\n",
        "      if frame_resized is None:\n",
        "        print(f\"There was no resizing {videos[i]}\")\n",
        "        break\n",
        "      else:\n",
        "        frame_resized = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n",
        "        frame_resized = frame_resized / 255.0\n",
        "        frames.append(frame_resized)\n",
        "        if len(frames) >= max_frames:\n",
        "          break\n",
        "      while len(frames) < max_frames:\n",
        "        frames.append(np.zeros((112, 112, 3)))\n",
        "    dataset.append(np.array(frames))\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_features = extract_features(\"/content/samples/\")\n",
        "for item in video_features:\n",
        "  if item is None or np.isnan(item).any() or np.isnan(item).any() or np.isinf(item).any():\n",
        "    print(\"None\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "AkpYMPDkx4bQ",
        "outputId": "803a35d8-eb4e-4d40-f925-fa24327afb72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:18<00:00,  5.49it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32CEearlvfnF"
      },
      "source": [
        "Парсим файл annotations из датасета, который содержит общую информацию, в том числе и перевод РЖЯ на русский вербальный"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJOKDdEOsbz5"
      },
      "outputs": [],
      "source": [
        "with open(\"annotations.txt\", \"rt\", encoding=\"utf-8\") as file:\n",
        "  text = file.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "iE4xg092tvY6"
      },
      "outputs": [],
      "source": [
        "text_splitted = re.split(\"\\t|\\n\", text)\n",
        "text = [text_splitted[i] for i in range(8, len(text_splitted), 7)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nZWP4Jjcvx14",
        "outputId": "59690ec4-7205-4bff-bc6c-fd53c19e8819"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "classes = len(set(text[:100]))\n",
        "classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Lvu7nlJOJ3Z"
      },
      "source": [
        "Извлекаем категории для классификации, создаем на основе них массив"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpcKcWxl6dZa",
        "outputId": "11c58205-e43e-4010-fdb8-f8044022af52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 492867.69it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "labels_dict = {}\n",
        "count = 0\n",
        "labels = text[:100]\n",
        "for i in tqdm(range(len(labels))):\n",
        "  if labels[i] not in labels_dict:\n",
        "    labels_dict[labels[i]] = count\n",
        "    count += 1\n",
        "y_labels = [[labels_dict[labels[i]]] for i in range(len(labels))]\n",
        "y_labels_categorical = to_categorical(y_labels, num_classes=classes)\n",
        "y_labels_categorical = np.array(y_labels_categorical)\n",
        "y_labels_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7_i29daYeol"
      },
      "source": [
        "Прописываем слои модели CNN + RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hk9Rp38TSglJ"
      },
      "outputs": [],
      "source": [
        "cnn_model = Sequential()\n",
        "cnn_model.add(Input(shape=(112, 112, 3)))\n",
        "cnn_model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "cnn_model.add(MaxPooling2D((2, 2)))\n",
        "cnn_model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "cnn_model.add(MaxPooling2D((2, 2)))\n",
        "cnn_model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "cnn_model.add(MaxPooling2D((2, 2)))\n",
        "cnn_model.add(Flatten())\n",
        "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDdQ5mQeu1xA"
      },
      "outputs": [],
      "source": [
        "history = cnn_model.fit(video_features, batch_size=16, epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "На данный момент решаю проблему с None значениями в тензорах при парсинге датасета. Пробовал использовать как и первичный датасет Slovo, так и resize версию, а также делать обработку ошибок на разных этапах предобработки видео, пока что значения None в выборках сохраняются\n"
      ],
      "metadata": {
        "id": "O5heb1NUC25z"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOiJ+ZdtYhEg4Z97ZOqxcjW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}